# ğŸ”¬ Observatoire des mÃ©dias

Analyse automatique du narratif fÃ©ministe dans les mÃ©dias franÃ§ais.

## ğŸ“‹ Description

Cet observatoire mesure automatiquement Ã  quel point les mÃ©dias reprennent le narratif fÃ©ministe militant, article par article, puis mÃ©dia par mÃ©dia. Il collecte les articles, analyse leur contenu et gÃ©nÃ¨re des statistiques visuelles via un dashboard web.

## ğŸ—ï¸ Architecture

Le projet suit un pipeline en 4 Ã©tapes :

1. **Collecte d'URLs** : Recherche d'articles via moteurs de recherche
2. **RÃ©cupÃ©ration** : TÃ©lÃ©chargement et stockage du HTML
3. **Parsing** : Extraction du texte et mÃ©tadonnÃ©es
4. **Analyse** : Calcul des scores idÃ©ologiques et gÃ©nÃ©ration de statistiques

## ğŸ“ Structure du projet

```
observatoire_medias/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ medias.yml              # Liste des mÃ©dias & domaines
â”‚   â”œâ”€â”€ keywords.yml            # Mots-clÃ©s fÃ©ministes / Ã©quilibrants
â”‚   â””â”€â”€ search_providers.yml    # Configuration des APIs de recherche
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ urls_raw.csv            # URLs brutes collectÃ©es
â”‚   â”œâ”€â”€ urls_clean.csv          # URLs uniques
â”‚   â”œâ”€â”€ raw_html/               # HTML brut tÃ©lÃ©chargÃ©
â”‚   â”œâ”€â”€ articles_clean.csv      # Articles parsÃ©s
â”‚   â”œâ”€â”€ scores.csv              # Scores par article
â”‚   â”œâ”€â”€ stats_daily.json        # Statistiques agrÃ©gÃ©es
â”‚   â””â”€â”€ fetch_log.csv           # Log des tÃ©lÃ©chargements
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collect_urls.py         # Collecte d'URLs
â”‚   â”œâ”€â”€ fetch_articles.py       # TÃ©lÃ©chargement HTML
â”‚   â”œâ”€â”€ parse_articles.py       # Extraction du texte
â”‚   â”œâ”€â”€ analyze_articles.py     # Calcul des scores
â”‚   â”œâ”€â”€ build_stats.py          # GÃ©nÃ©ration des stats
â”‚   â”œâ”€â”€ run_pipeline.py         # Script d'orchestration du pipeline complet
â”‚   â”œâ”€â”€ reset_data.py           # RÃ©initialisation des donnÃ©es
â”‚   â”œâ”€â”€ audit_parsing.py        # Audit de qualitÃ© du parsing
â”‚   â”œâ”€â”€ test_sensitivity.py     # Tests de sensibilitÃ© des mots-clÃ©s
â”‚   â”œâ”€â”€ filter_old_articles.py  # Filtrage des articles par date
â”‚   â”œâ”€â”€ remove_duplicates.py    # Suppression des doublons
â”‚   â”œâ”€â”€ statistical_tests.py    # Tests statistiques
â”‚   â””â”€â”€ validation_inter_codage.py # Validation inter-codage
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py                  # API Flask
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ index.html          # Dashboard frontend
â”‚       â”œâ”€â”€ app.js              # Application JavaScript
â”‚       â””â”€â”€ style.css           # Styles CSS
â”œâ”€â”€ env.example.txt             # Exemple de configuration (Ã  copier en .env)
â”œâ”€â”€ run_pipeline.bat            # Script batch Windows pour lancer le pipeline
â”œâ”€â”€ start_dashboard.bat         # Script batch Windows pour lancer le dashboard
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ README.md                   # Ce fichier
â”œâ”€â”€ QUICKSTART.md               # Guide de dÃ©marrage rapide
â”œâ”€â”€ METHODOLOGIE.md             # Documentation mÃ©thodologique
â””â”€â”€ RESET_GUIDE.md              # Guide de rÃ©initialisation
```

## ğŸš€ Installation

### 1. Cloner ou tÃ©lÃ©charger le projet

```bash
cd "Observatoire media"
```

### 2. Installer les dÃ©pendances Python

```bash
pip install -r requirements.txt
```

### 2bis. Installer les navigateurs Playwright (recommandÃ©)

Pour contourner les protections anti-bot (notamment France 24), Playwright est utilisÃ© automatiquement :

```bash
playwright install chromium
```

**Note** : Si Playwright n'est pas installÃ©, le script utilisera `requests` en fallback, mais certains sites peuvent bloquer les requÃªtes automatisÃ©es.

### 3. Configuration

Copiez `env.example.txt` vers `.env` et configurez vos clÃ©s API si nÃ©cessaire :

**Sur Windows :**
```bash
copy env.example.txt .env
```

**Sur Linux/Mac :**
```bash
cp env.example.txt .env
```

**Note** : Par dÃ©faut, le script utilise DuckDuckGo qui ne nÃ©cessite pas de clÃ© API. Vous pouvez utiliser SerpAPI ou Bing API pour de meilleurs rÃ©sultats.

### 4. Personnaliser la configuration

- **`config/medias.yml`** : Ajoutez/modifiez les mÃ©dias Ã  analyser
- **`config/keywords.yml`** : Personnalisez les mots-clÃ©s fÃ©ministes et Ã©quilibrants
- **`config/search_providers.yml`** : Configurez les providers de recherche

## ğŸ“Š Utilisation

### Pipeline complet

**MÃ©thode recommandÃ©e (automatique) :**

**Sur Windows :**
```bash
run_pipeline.bat
```

**Sur Linux/Mac :**
```bash
python scripts/run_pipeline.py
```

**MÃ©thode manuelle (Ã©tape par Ã©tape) :**

```bash
# 1. Collecte des URLs
python scripts/collect_urls.py

# 2. TÃ©lÃ©chargement des articles
python scripts/fetch_articles.py

# 3. Parsing des articles
python scripts/parse_articles.py

# 4. Analyse et scoring
python scripts/analyze_articles.py

# 5. GÃ©nÃ©ration des statistiques
python scripts/build_stats.py
```

### Lancement du dashboard

**Sur Windows :**
```bash
start_dashboard.bat
```

**Sur Linux/Mac :**
```bash
python app/api.py
```

Puis ouvrez votre navigateur Ã  l'adresse : `http://localhost:5000`

### Scripts utilitaires

Le projet inclut Ã©galement plusieurs scripts utilitaires pour la maintenance des donnÃ©es :

- **`scripts/filter_franceculture.py`** : Supprime tous les articles de franceculture.fr des donnÃ©es
- **`scripts/filter_old_articles.py`** : Supprime les articles publiÃ©s avant 2000 ou aprÃ¨s 2025
- **`scripts/remove_duplicates.py`** : DÃ©tecte et supprime les doublons dans tous les fichiers CSV
- **`scripts/statistical_tests.py`** : Effectue des tests statistiques sur les donnÃ©es
- **`scripts/validation_inter_codage.py`** : Outil de validation inter-codage pour la qualitÃ© des donnÃ©es

## ğŸ”„ Automatisation

Pour automatiser le pipeline sur votre serveur, crÃ©ez un script cron ou une tÃ¢che planifiÃ©e :

**Sur Windows (TÃ¢che planifiÃ©e) :**
- Ouvrez le Planificateur de tÃ¢ches Windows
- CrÃ©ez une tÃ¢che qui exÃ©cute `run_pipeline.bat` chaque jour Ã  l'heure souhaitÃ©e

**Sur Linux/Mac (Cron) :**
```bash
# Exemple de crontab (exÃ©cution chaque nuit Ã  3h)
0 3 * * * cd /chemin/vers/observatoire_medias && python scripts/run_pipeline.py
```

**Note** : Il est recommandÃ© d'utiliser `run_pipeline.py` plutÃ´t que d'exÃ©cuter les scripts individuellement, car il gÃ¨re automatiquement les erreurs et fournit un rÃ©sumÃ© dÃ©taillÃ©.

## ğŸ“ˆ MÃ©triques calculÃ©es

Pour chaque article, l'observatoire calcule :

- **Score fÃ©ministe** : Nombre d'occurrences des mots-clÃ©s fÃ©ministes
- **Score Ã©quilibrant** : Nombre d'occurrences des mots-clÃ©s Ã©quilibrants (sources neutres, mention des victimes masculines, etc.)
- **Indice militant** : `score_feministe - score_balance`
- **DensitÃ©** : Score normalisÃ© par rapport Ã  la longueur du texte

Les statistiques agrÃ©gÃ©es incluent :

- Indice militant moyen par mÃ©dia
- Nombre d'articles analysÃ©s
- Pourcentage d'articles sans mots-clÃ©s Ã©quilibrants
- Top 10 des articles les plus militants

## âš–ï¸ Aspects lÃ©gaux

**Important** : Ce projet respecte les bonnes pratiques de scraping web :

- âœ… Respect des `robots.txt`
- âœ… Limitation des requÃªtes (dÃ©lais entre requÃªtes)
- âœ… Ne republie pas le contenu intÃ©gral des articles
- âœ… Affiche uniquement les mÃ©tadonnÃ©es (URL, titre, scores)

**Note** : Assurez-vous de respecter les conditions d'utilisation des sites web et des APIs utilisÃ©es.

## ğŸ”¬ Validation et Rigueur MÃ©thodologique

Pour garantir la qualitÃ© et la rigueur des rÃ©sultats, plusieurs outils sont disponibles :

### Audit du parsing

VÃ©rifiez rÃ©guliÃ¨rement la qualitÃ© de l'extraction du texte :

```bash
python scripts/audit_parsing.py
```

Ce script gÃ©nÃ¨re un rapport HTML interactif permettant de comparer manuellement les articles parsÃ©s avec les originaux.

### Tests de sensibilitÃ©

Testez l'impact des mots-clÃ©s sur les rÃ©sultats :

```bash
python scripts/test_sensitivity.py
```

Ce script analyse :
- La frÃ©quence d'utilisation de chaque mot-clÃ©
- L'impact estimÃ© de la suppression de mots-clÃ©s
- Les mots-clÃ©s jamais trouvÃ©s (candidats Ã  la suppression)

### Documentation mÃ©thodologique

Consultez `METHODOLOGIE.md` pour :
- La justification de chaque mot-clÃ©
- Les limites et biais connus
- Les recommandations d'interprÃ©tation
- Les amÃ©liorations futures prÃ©vues

## ğŸ› ï¸ DÃ©veloppement

### Ajouter un nouveau mÃ©dia

Ã‰ditez `config/medias.yml` et ajoutez :

```yaml
- name: "Nom du mÃ©dia"
  domain: "domaine.fr"
```

### Ajouter des mots-clÃ©s

Ã‰ditez `config/keywords.yml` et ajoutez vos mots-clÃ©s dans les sections appropriÃ©es.

### Personnaliser le dashboard

Les fichiers frontend sont dans `app/static/` :
- `index.html` : Structure HTML
- `app.js` : Logique JavaScript (Chart.js)
- `style.css` : Styles CSS

## ğŸ“ Notes

- Les donnÃ©es sont stockÃ©es localement dans le dossier `data/`
- Le dashboard se met Ã  jour automatiquement toutes les 5 minutes
- Les scripts gÃ¨rent automatiquement les doublons et les erreurs
- Utilisez `run_pipeline.bat` (Windows) ou `run_pipeline.py` (Linux/Mac) pour exÃ©cuter le pipeline complet en une seule commande
- Le script d'orchestration vous permet de continuer malgrÃ© les erreurs et affiche un rÃ©sumÃ© dÃ©taillÃ© Ã  la fin

## ğŸ¤ Contribution

Ce projet est modulaire et peut Ãªtre Ã©tendu facilement :
- Ajout de nouveaux providers de recherche
- AmÃ©lioration des parseurs HTML spÃ©cifiques par mÃ©dia
- Ajout de nouvelles mÃ©triques d'analyse
- Export des donnÃ©es vers MongoDB ou autres bases

## ğŸ“„ Licence

Ce projet est fourni Ã  des fins d'analyse et de recherche. Respectez les droits d'auteur et les conditions d'utilisation des sites web analysÃ©s.


